"0",""
"0","trip_kl_cuisine <- read_csv(""./data/trip_kl_cuisine.csv"")"
"0",""
"0","google_kl_cuisine <- read_csv(""./data/google_kl_cuisine.csv"")"
"0",""
"0","google_rating_words <- google_kl_cuisine |> "
"0","  select(rowid, rating, review) |> "
"0","  unnest_tokens(word, review) |> "
"0","  # mutate(word = SnowballC::wordStem(word, language = ""porter"")) |> "
"0","  anti_join(stop_words, by = ""word"") |>"
"0","  add_count(word, rating) "
"0",""
"0","trip_rating_words <- trip_kl_cuisine |> "
"0","  select(rowid, review, rating) |> "
"0","  unnest_tokens(word, review) |> "
"0","  # mutate(word = SnowballC::wordStem(word, language = ""porter"")) |> "
"0","  anti_join(stop_words, by = ""word"") |>"
"0","  add_count(word, rating) "
"0",""
"0","google_rating_bigrams <- google_kl_cuisine |> "
"0","  select(rowid, rating, review, cuisine) |> "
"0","  unnest_tokens(bigram, review, token = ""ngrams"", n = 2) |> "
"0","  filter(!is.na(bigram)) |> "
"0","  add_count(bigram) |> "
"0","  separate(bigram, c(""word1"", ""word2""), sep = "" "") |> "
"0","  filter(!word1 %in% stop_words$word) |> "
"0","  filter(!word2 %in% stop_words$word) |> "
"0","  count(word1, word2, rating, sort = TRUE) |> "
"0","  unite(bigram, word1, word2, sep = "" "") |> "
"0","  bind_tf_idf(bigram, rating, n)"
"0","  "
"0","trip_rating_bigrams <- trip_kl_cuisine |> "
"0","  select(rowid, rating, review, cuisine) |> "
"0","  unnest_tokens(bigram, review, token = ""ngrams"", n = 2) |> "
"0","  filter(!is.na(bigram)) |> "
"0","  add_count(bigram) |> "
"0","  separate(bigram, c(""word1"", ""word2""), sep = "" "") |> "
"0","  filter(!word1 %in% stop_words$word) |> "
"0","  filter(!word2 %in% stop_words$word) |> "
"0","  count(word1, word2, rating, sort = TRUE) |> "
"0","  unite(bigram, word1, word2, sep = "" "") |> "
"0","  bind_tf_idf(bigram, rating, n)  "
"0",""
