[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "",
    "text": "A common refrain in this postmodern age is that online reviews are useless.\nToday, we’re looking at two different sets of scraped restaurant reviews to determine to what extent that is true. Restaurant reviews from Google and Trip Advisor in Malaysia were scraped by Ng Choon Khon using the Selenium library.\nBelow, we’ve plotted out the restaurants found in both datasets according to the number of reviews and their mean rating. Immediately, we note an unnatural pattern in the Google dataset: Google limits Selenium to only being able to scrape around 300 reviews per restaurant, at most.\nWhilst this impacts and limits the dataset, we should still make the best use of it we can: Google’s official API only allows five reviews to be extracted per restaurant because data freely given to the world must be paywalled and sold back to you.\nThis analysis is ultimately meant to better understanding of Google’s and Trip Advisor’s review platforms from a consumer perspective, in order to choose more satisfactory restaurants.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s review the limitations once more, before we look into these datasets:\n\nWhat Google’s dataset is representative of cannot be readily explained. For many restaurants, only their first 300 most “relevant” reviews have been extracted. Google determines “relevance” by using a combination of recency, quality (word count, images) and whether or not a review was regarded by the community as helpful.\nBoth Google maps and Trip Advisor are principally English language platforms when the language isn’t regularly used by the majority of the population. Upon a cursory inspection, there are very few reviews in Malay in Google (0.28%) and even less in Trip Advisor (0.14%). This is extremely different from even urban demographics (where there are proportionally more minorities, and consequently, English speakers). This bias is more understandable on Trip Advisor than it is on Google.\nThe price range is missing from this dataset. This is unfortunate because price is one of the main topics mentioned in reviews. If I were to rescrape the data, I would definitely prioritise getting the price range.\nThese reviews were extracted three years ago: some of these restaurants have closed, or have changed how they operate.\nWhilst reviews themselves are largely meant to informational, expressive or cautionary, review platforms are mired in layers of obfuscation, gamification and marketing. Additionally, Google’s reviews are generally less policed than Trip Advisor’s, with notable instances of scams and bribed reviews. Additionally, reviews are further affected by prevailing social mores (we discuss the skew towards five stars below)."
  },
  {
    "objectID": "index.html#introduction-and-overview",
    "href": "index.html#introduction-and-overview",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "",
    "text": "A common refrain in this postmodern age is that online reviews are useless.\nToday, we’re looking at two different sets of scraped restaurant reviews to determine to what extent that is true. Restaurant reviews from Google and Trip Advisor in Malaysia were scraped by Ng Choon Khon using the Selenium library.\nBelow, we’ve plotted out the restaurants found in both datasets according to the number of reviews and their mean rating. Immediately, we note an unnatural pattern in the Google dataset: Google limits Selenium to only being able to scrape around 300 reviews per restaurant, at most.\nWhilst this impacts and limits the dataset, we should still make the best use of it we can: Google’s official API only allows five reviews to be extracted per restaurant because data freely given to the world must be paywalled and sold back to you.\nThis analysis is ultimately meant to better understanding of Google’s and Trip Advisor’s review platforms from a consumer perspective, in order to choose more satisfactory restaurants.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s review the limitations once more, before we look into these datasets:\n\nWhat Google’s dataset is representative of cannot be readily explained. For many restaurants, only their first 300 most “relevant” reviews have been extracted. Google determines “relevance” by using a combination of recency, quality (word count, images) and whether or not a review was regarded by the community as helpful.\nBoth Google maps and Trip Advisor are principally English language platforms when the language isn’t regularly used by the majority of the population. Upon a cursory inspection, there are very few reviews in Malay in Google (0.28%) and even less in Trip Advisor (0.14%). This is extremely different from even urban demographics (where there are proportionally more minorities, and consequently, English speakers). This bias is more understandable on Trip Advisor than it is on Google.\nThe price range is missing from this dataset. This is unfortunate because price is one of the main topics mentioned in reviews. If I were to rescrape the data, I would definitely prioritise getting the price range.\nThese reviews were extracted three years ago: some of these restaurants have closed, or have changed how they operate.\nWhilst reviews themselves are largely meant to informational, expressive or cautionary, review platforms are mired in layers of obfuscation, gamification and marketing. Additionally, Google’s reviews are generally less policed than Trip Advisor’s, with notable instances of scams and bribed reviews. Additionally, reviews are further affected by prevailing social mores (we discuss the skew towards five stars below)."
  },
  {
    "objectID": "index.html#comparisons-of-average-ratings",
    "href": "index.html#comparisons-of-average-ratings",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Comparisons of average ratings",
    "text": "Comparisons of average ratings\nWith reference to the plots below, ratings are skewed towards the higher end: the mean rating of restaurants on Google is 4.16 and the mean rating on Trip Advisor is 4.22. The median and mode for both datasets is 5.\nIt really could be said that the default review rating is five stars. This means that restaurant reviews on these platforms are quite lenient. It is hard for me to believe that half of all reviews were about truly exceptional dining experiences: 51.87% of all ratings in the Google dataset for the Klang Valley (KL, PJ and Shah Alam in the datasets) are five stars; in Trip Advisor, it was 52.79%.\n\n\n\n\n\n\n\n\n\n\n\nReviews are limited (in every sense of the word) to a one-to-five scale. In the scatterplots below, we note that almost all restaurants mostly receive five stars (blue) or four stars (green). This does seem to indicate that restaurant ratings are not very good at distinguishing between restaurants."
  },
  {
    "objectID": "index.html#adding-cuisine",
    "href": "index.html#adding-cuisine",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Adding cuisine",
    "text": "Adding cuisine\nThese are the columns present in the Google dataset:\n\n\n[1] \"author\"     \"rating\"     \"review\"     \"restaurant\" \"location\"  \n\n\nTrip Advisor has additional columns for review title and date.\nLet’s add a column for cuisine (the code can be downloaded at the top of the page, but it was a lot of manual work) to increase interpretability and to maximise the usefulness of the data. We’ll narrow down the scope to locations in the Klang Valley (KL, PJ and Shah Alam, in the datasets; since I’m most familiar with and most interested in this metro).\nDetermining the cuisine of a restaurant was mostly fairly obvious, and the categories hopefully self-explanatory. Additional notes on the coding of these cuisines may be found in the appendices.\nLet’s start first with an overview of both datasets, now with cuisines included. From the plot below, we see that:\n\nSouth Asian, Chinese, Casual Western, Japanese and Bars are the most commonly-reviewed restaurants in the Klang Valley. These are not the most common nor the most commonly-visited restaurants (hawker stalls).\nChinese, Casual Western, Malaysian and Thai are the lowest-rated cuisines.\nFusion, Other Upmarket (experiential dining or unspecified “international” cuisine) and bars have the highest ratings, with 60% or more of all reviews being five stars.\nTrip Advisor and Google reviewers differ the most on their opinions of Levantine, Casual Western and Japanese restaurants. With regards to Levantine food, in my opinion at least, it might be a case of “good for Malaysia”, but not necessarily good compared to outside of it.\nThe x-axes on the plots below show the percentage of reviews that are five stars by cuisine. This actually provides much more differentiation than just the mean rating (which is reflected in the colours below)."
  },
  {
    "objectID": "index.html#restaurants-in-both-google-and-trip",
    "href": "index.html#restaurants-in-both-google-and-trip",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Restaurants in both Google and Trip",
    "text": "Restaurants in both Google and Trip\nLet’s investigate a bit more by looking at restaurants that appear in both the Google and Trip datasets.\nBelow, we have plotted restaurants based on their mean ratings on Google and Trip Advisor. The globalised nature (with such heavy representation from casual western restaurants) of the Malaysian food scene seems to result in Google (which is used more heavily by locals) and Trip Advisor (which is used more often by travellers) agreeing more than not.\nLooking at the top-right quadrant, we see that the restaurants rated most highly by Google and Trip Advisor are mostly fine dining: Sushi Hibiki is a high-end omakase restaurant and seems to be regarded as the best meal in the Klang Valley; DC Restaurant has one Michelin star. Sausage Kl Cafe and Grill, however, was a restaurant specialising in full English breakfast. And Antipodean is a cafe that is, to me, a solid 3.5/5; but it still has around the same Trip Advisor rating as Dewakan, which has two Michelin stars.\nWe’ll look into this more in next week’s section of the report, but it appears that the commonality of five-star reviews indicates that the mean rating might be more an indicator of expectations being met, than any true excellence.\n\n\n\n\nClick image for full size\n\n\n\nWhat becomes clearer when we re-plot the restaurants, this time using percentage of ratings that are five stars, the distinction between fine dining and more casual restaurants is much clearer. Fine dining restaurants tend to have above 50% of their reviews being five stars in both Trip and Google.\nThe restaurants in the “fine dining” group have higher floors and ceilings, when it comes to the percentage of ratings that are five stars. This is why lacking price range in this dataset is such a shame, as it seems like these two groups should be graded on their own curves.\nWe also see how Google reviewers are stricter (less lenient), with restaurants struggling to get above 70% five-star reviews. Though, as mentioned this isn’t any particular mark of quality.\nAlso to be investigated further is to what extent restaurants in the “fine dining” achieve their higher scores due to better service and environments, as opposed to food quality.\n\n\n\n\nClick image for full size"
  },
  {
    "objectID": "index.html#conclusions-part-one",
    "href": "index.html#conclusions-part-one",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Conclusions: Part one",
    "text": "Conclusions: Part one\nLet’s review what we’ve learnt so far; though we probably already knew some of these things instinctually, it is still nice to get confirmation:\n\nReviews skew very heavily towards five stars. More than half of all reviews give five stars. This means that Google Maps and TripAdvisor are not useful in determining where one should eat since five stars could mean anything from “met expectations” to “truly exceptional”.\nRe-sorting (lowest, most recent) and filtering reviews will likely provide more informative reviews on Google. There is no real reason to accept their default sorting by “relevance” as you can pay for visibility, pay for reviews, and pay to remove reviews.\nHowever, this means that we’re still engaging with reviews as individual data points. Even looking at the review summary will not always be helpful, since having five-star reviews be less than 50% of your total is more an indicator that the restaurant is not fine dining, than any other indicator of quality.\nOutside of the home, hawker centres and coffee shops are places where food is most commonly consumed. Yet these businesses are not reviewed with anywhere the same frequency as the casual western eateries or chinese restaurants/dai chows. It is difficult (by design?) to mark individual hawkers since they operate from within the premises of another business. Additionally, hawkers are much less likely to engage with Google or Trip Advisor to curate or market their online presence, leading to these platforms being blind to the needs of hawkers and continue to cater towards restaurants (who might actual have marketing budgets).\n\nRare is the occasion that I, whilst searching on Google or Trip Advisor, find a truly exceptional meal. My most memorable experiences have mostly been the result of personal recommendations or curated lists from trusted reviewers. I’m starting to think that the main purpose of review platforms is marketing."
  },
  {
    "objectID": "index.html#appendices",
    "href": "index.html#appendices",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Appendices",
    "text": "Appendices\n\nNotes on cuisine\nWith reference to the cleaning script for determining the cuisine of a restaurant, there are few things to bear in mind in trying to update or improve it.\nI have made a distinction between Malay and Malaysian cuisines. This difference can be boiled down to Chef Wan (Malay) vs. Madan Kwan (Malaysian). A Hainan Kopitiam would be considered as Malaysian.\nA few more points for the ordering of arguments within the case_when statement:\n“Other Upmarket” is mostly expensive experiential dining, with some tourist traps. In this category are Dining in the Dark and Plane in KL. I’ve also included Turkish food under the “Levantine” umbrella.\n“Fusion” restaurants are explicitly fusion restaurants, with the word “fusion” in their names or showing up in a proportion of reviews. The same is true for buffet restaurants (which were numerous enough in the Trip Advisor dataset to warrant their own category).\nI have considered South Asian buffet restaurants to be South Asian restaurants. I And I do not consider hotel buffets to be a type of fusion restaurant, despite all the types of food they might serve. Additionally, when altering the cleaning script, make sure that the argument for grills is before that for bars (because of “barbecue”).\nThe Google and Trip Advisor datasets for the Klang Valley have a fairly comparable number of reviews: 77,864 in Google and 78,925 in Trip Advisor.\n\n\n\n\n\n\n\n\n\n\nTrip Advisor reviewers tended to review far more bars, buffets (including hotel buffets), cafes, fusion, Japanese and unspecified upmarket restaurants than Google reviewers. This is commonsensical since Trip Advisor tends to have travellers using it.\n\n\n\nReference tables\nBelow are reference tables for the restaurants used in this analysis.\n\nGoogle: restaurants in the Klang Valley\nSorted in descending order, according to mean rating.\n\n\n\n\n\n\n\n\n\nTrip Advisor: restaurants in the Klang Valley\nSorted in descending order, according to mean rating."
  },
  {
    "objectID": "part_two_words.html",
    "href": "part_two_words.html",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "",
    "text": "In this second part of our analysis, we’ll be doing some text analytics. To recap, we are using data scraped by Ng Choon Khon containing restaurant reviews in Malaysia on Google and Trip Advisor. Take a look at the first part of this report to see the analysis of ratings as well as the dataset limitations.\nLet’s start with an overview of the most common bigrams (two consecutive words) that appear in Google reviews, broken down by rating.\nWhilst there isn’t too much in the plot below that is unexpected, it should be noted that our collective vocabulary, when it comes to restaurant reviews, is quite limited: “nice food” could indicate anything between three stars and five. Though we could argue that reviewers are being way too lenient by classing “nice food” as five stars.\nService, and not just food quality, is a major determinant in one-star ratings. This perhaps could be one of the reasons why fine dining restaurants have higher floors and ceilings for their ratings than more casual dining options.\n\n\n\n\n\n\n\n\n\n\n\nWhilst ratings might be very lenient overall – cheapening a five-star rating – we can at least say that there are definitely also qualitative differences between five-star and one-star reviews."
  },
  {
    "objectID": "part_two_words.html#words",
    "href": "part_two_words.html#words",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "",
    "text": "In this second part of our analysis, we’ll be doing some text analytics. To recap, we are using data scraped by Ng Choon Khon containing restaurant reviews in Malaysia on Google and Trip Advisor. Take a look at the first part of this report to see the analysis of ratings as well as the dataset limitations.\nLet’s start with an overview of the most common bigrams (two consecutive words) that appear in Google reviews, broken down by rating.\nWhilst there isn’t too much in the plot below that is unexpected, it should be noted that our collective vocabulary, when it comes to restaurant reviews, is quite limited: “nice food” could indicate anything between three stars and five. Though we could argue that reviewers are being way too lenient by classing “nice food” as five stars.\nService, and not just food quality, is a major determinant in one-star ratings. This perhaps could be one of the reasons why fine dining restaurants have higher floors and ceilings for their ratings than more casual dining options.\n\n\n\n\n\n\n\n\n\n\n\nWhilst ratings might be very lenient overall – cheapening a five-star rating – we can at least say that there are definitely also qualitative differences between five-star and one-star reviews."
  },
  {
    "objectID": "part_two_words.html#one-star-and-five-star-reviews-of-chinese-restaurants",
    "href": "part_two_words.html#one-star-and-five-star-reviews-of-chinese-restaurants",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "One-star and five-star reviews of Chinese restaurants",
    "text": "One-star and five-star reviews of Chinese restaurants\nLet’s dig a little deeper. As noted in the previous part, Chinese and Casual Western restaurants – overall – have the highest numbers of reviews and some of the lowest mean ratings across all cuisines. Let’s take advantage of this by looking more closely at one single slice of the data.\nBelow, is a network graph of words used in one-star reviews of Chinese restaurants in the Klang Valley. The thickness of the lines between words indicates the number of times a word pairing has shown up in reviews. The transparency of the lines indicates the strength of the correlation between those two words. Key topics have been highlighted by me.\nWe see a combination of quite undesirable experiences: smelly, pricey, not fresh, rude, long waits and poor quality. Additionally, service and the overall “experience” show up prominently as well (especially when it relates to events such as Chinese New Year, which often sees large banquets for friends, family and associates).\n\n\n\n\nClick image for full size\n\n\n\nLet’s look at the flipside and see what reviewers said about five-star dining experiences in Chinese restaurants. As with the plot above, line thickness shows the frequency of the word pair and the transparency indicates the correlation. Key topics once again highlighted by me.\nWhilst five-star reviews of Chinese restaurants are much more numerous, we don’t necessarily see a greater variety of expression (just more foods mentioned), we see that points of failure are very similar to points of success for Chinese restaurants: freshness, friendly service, waiting times and reasonable pricing. We also see a key phrase that we will delve into in a later section: “highly recommended”.\n\n\n\n\nClick image for full size\n\n\n\nAs a whole, Chinese restaurants seem to be judged by Google reviewers on quite a consistent set of criteria."
  },
  {
    "objectID": "part_two_words.html#topic-modelling-and-expectations",
    "href": "part_two_words.html#topic-modelling-and-expectations",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Topic modelling and expectations",
    "text": "Topic modelling and expectations\nSince reviews are so heavily skewed towards 5 stars, let’s use topic modelling to break down reviews into just two groups which I have termed Recommended and Everything else. This will hopefully sort out all the five- and four-star reviews that are not actual recommendations.\nBelow, the per-topic-per-word probabilities of bigrams in the Google dataset have been plotted. The x-axes indicate the probability of each bigram appearing in reviews under each topic.\nBigrams have been used here because individual words are not as informative (“service” vs. “excellent service”). As mentioned, our collective vocabulary is quite limited when it comes to food: “fine dining” is used both as a compliment and as a mocking pejorative.\n\n\n\n\n\n\n\n\n\n\n\nLet’s take a closer look at individual bigrams. We’ll start with some of the most common foods that show up in Google reviews. With the plots below, the important thing is to compare the relative per-topic probabilities of each of the bigrams that occur in each topic i.e. how probable it is that a particular food will be in a “Recommended” review.\nRestaurants seem to have the worst performance with chicken rice, fried rice, char siew, dim sum and roast pork. Amongst cuisines, Indian and Italian food seem to be recommended more often than not; the opposite is true for Chinese restaurants.\nPerhaps reviewers are less generous with foods they are familiar with. I know I am: I’ve had extremely good char siew and roast pork (that can be easily and readily accessed) and can be uncharitable and judgemental when they are done poorly.\nGiven the low percentage of reviews that use Malay that we mentioned in the previous part – many of the most common foods here are not halal at all. This underlines that the demographics of Google reviewers (who are already much more likely to be locals than Trip Advisor reviewers) are skewed heavily towards minorities.\n\n\n\n\n\n\n\n\n\n\n\nThe next plot below shows some of the most common general descriptors (not specific to food) of restaurants.\n“Friendly staff” and “nice food”, more often than not, are complimentary terms, but do by no means guarantee a positive review or a recommendation. Likewise, having a “nice environment” is important, but nowhere as important as having “excellent food” or “excellent service”.\nBringing up “food quality” is more likely a pejorative than it is not. If service is very important to you, the terms “excellent service” and “friendly staff” are good distinguishers in Google reviews. Unfortunately, a lot of people to whom service is very important are unable to acknowledge this fact about themselves.\n\n\n\n\n\n\n\n\n\n\n\nHowever, this isn’t all that applicable to real life, since you can’t search all reviews across all restaurants for keywords. Google Maps does not work the same way Google Search does (at least before it became useless). You can only search for keywords within the reviews of a single restaurant.\nThis is another point in favour of online reviews just being a marketing ploy. Not to say that marketing ploys cannot be informative, just that their information is compromised.\nThere is, however, one keyword that does work."
  },
  {
    "objectID": "part_two_words.html#highly-recommended-restaurant-sic",
    "href": "part_two_words.html#highly-recommended-restaurant-sic",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "“Highly recommended restaurant” (sic)",
    "text": "“Highly recommended restaurant” (sic)\n\n\n\n\nWhat directory mode looks like\n\n\n\nType in “highly recommended restaurant” (sic) into Google Maps (or “recommended restaurant” on iOS) and see what you get. I get a list of some pretty good restaurants, with no photos. I don’t agree with every entry, this “directory” mode is probably the best (but still flawed) performance I’ve seen from Google Maps in a long time.\nNow, this may seem like we’ve somehow gamed the system, but to bring us back down to Earth, this list of highly recommended restaurants is actually still part of the play, according to Gemini (Google Maps Support has no real answers on this topic):\n\nWhen you type “highly recommend restaurant” into the search bar, Google Maps interprets those words as keywords rather than a command. Instead of looking for a specific badge, the app uses its algoritm to build a list based on several “trust signals.”\n\n\n\nKeyword matching (SEO) […] “This place is highly recommended” […]\nHigh “Prominence” Scores. Google defines “Prominence” as how well-known or important a business is. When you ass “highly recommended” to your search, the algorithm prioritizes restaurants with: high volume of 4.5+ star ratings. Mentions on “Best Of” lists […]. Heavy foot traffic (Google tracks how many people acturally visit the location).\nThe “Top Rated” Filter. By using that specific phrase, you are essentially triggering Google’s built-in Rating Filter. Google will automatically filter out businesses with low ratings (usually anything below a 4.0) […].\nMachine Learning & “Your Match”[…]\n\n\nThey have also included a “Review Snippet” so you can tell why a particular restaurant made it to this list. Also note from these screenshots that the actual rating is not that important: restaurants are in the range of 4.0 to 5.0, but that’s about it, as if Google also knows that the mean rating is not a particularly useful metric.\nConversely, when you type in “highly recommended restaurants” or just “highly recommended”,\n\nthe list looks different—often featuring large, swipeable photos—because Google switches from a standard “directory” mode to “Discovery Mode.” Google knows that when you use words like “highly recommended,” you aren’t just looking for an address; you’re looking for an experience.\n\nWhen not in “directory” mode, the factors that Google Maps takes into account are not desirable (at least by me):\n\n\nVisual “proof” of recommendation. Google’s AI specifically pulls photos it identifies as “high quality”\nThe “Discover Through Photos” feature. […] When you use subjective search terms (like highly recommended, beautiful, cozy), Google assumes yuou want to browse visually.\nAI Dish Matching\nHigh Engagement Signals. […] Google rewards businesses that have high engagement. If a restaurant has 1,000 photos uploaded by customers, Google has a huge library to make the search result look more attractive and “trustworthy” to you.\n\n\nThis is likely why searching for “best restaurant” yields such poor results. You’re probably getting results that are more easily manipulated and influenced i.e. upload a photo for a free ice cream.\nFor reference, Google Maps’s base algorithm (which is used when you type in “restaurants in area X”) relies on:\n\n\nDistance\nRelevance. […] Category matching, […] Menu and Attributes, […] Open Now\nProminence. […] Review velocity […] how ofren peole are leaving reviews. […] Web presence […]. SEO strength: the ranking of the restaurant’s actual website also matters.\nPersonalisation\n\n\nBut back to “directory” mode: even though you get more satisfactory results, bear in mind that the Google rating has already been taken into account twice: ratings are part of how Google calculates “Prominence” and the algorithm also applies a rating filter.\nThat it does not solely act like a keyword is likely to prevent more manipulation and SEO shenanigans. So far, I’ve only been able to trigger Directory mode with this one phrase. What else can trigger Directory mode on Google Maps? In these trying times, could some variation of “reasonable price restaurant” work?"
  },
  {
    "objectID": "part_two_words.html#conclusions-part-two",
    "href": "part_two_words.html#conclusions-part-two",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Conclusions part two",
    "text": "Conclusions part two\nOnline reviews are part of a highly-gamified ecosystem. Standard searches will leave you at the mercy of content pushed by SEO, influencers and black-box algorithms.\nWhilst there are ways around this, like directory mode, ultimately, the system fundamentally does not seem to be geared towards the needs of customers (especially not if you need tips and tricks just to get passable performance). Customisation occurs mostly on the back-end: there is no way to tell Google what ypu consider relevant to you. Instead, they glean this from your online footprint, believing you will unconsciously betray your wants and needs to them.\nTherein lies the rub. Just because you know my sex, my income, whether or not I’m pregnant, and can put me into one of their numerous categories and clusters does not mean you know me as a person, or even as a customer. You could argue that this widespread data theft might not lead to the best results for one person, but that it is used to produce apps and algorithms that are able to serve the majority well.\nBut I do not think Google Reviews serve the majority well. This has to do with the fact that online reviews are not solely about food. It is an “experience” that must be upsold and marketed to you. In trying to be Instagram, they have forgotten how to be a map, a directory. The wanton privileging of photos and influencer reels is not helpful when I just want a good meal.\nSo, are online reviews useful? Maybe 3/5."
  },
  {
    "objectID": "part_two_words.html#appendices",
    "href": "part_two_words.html#appendices",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "Appendices",
    "text": "Appendices\nEven within the much more verbose reviews on Trip Advisor, we still see that the language used is still very limited, irrespective of rating.\n\n\n\n\n\n\n\n\n\n\n\nJust as an interesting point, when we look at one-star Trip Advisor reviews for Casual Western restaurants, we see that the words “hot” and “cold” are quite prominent.\nI believe this has to do with underprepared and/or improperly microwaved food. Microwaved food, often bought from a food service or brought from a central kitchen, is one of the sad curses of modern dining. Waves of consolidation up and down the restaurant supply chain have left all hawkers in Singapore with one choice of yellow mee or only one type of bee hoon. In America, US Foods and Sysco have completely sewn up the supply chain, leading to all jalapeño poppers and mozarella sticks coast-to-coast to be the exact same.\nWhilst that level of corporate consolidation has not yet occurred in Malaysia, the process is nevertheless underway. This is something we must guard against, as homogeneity isn’t even prized in prison meals.\n\n\n\n\nClick image for full size\n\n\n\n“Cold” shows up again under one-star Google reviews of Casual Western restaurants, indicating poor attention to detail and/or rushed food preparation. Though it doesn’t necessarily point towards microwaved foods.\nAs a side note (in an appendix), there is a way to microwave food well – apparently using the defrost setting achieves the most even cooking.\n\n\n\n\nClick image for full size\n\n\n\nIn contrast, when we look at five-star reviews of Casual Western restaurants on Trip Advisor, we see a slew of foods which would suffer if the preparation were lacking: steaks, ribs, and even sausages would suffer from a microwave.\n\n\n\n\nClick image for full size"
  },
  {
    "objectID": "part_two_words.html#draft-words",
    "href": "part_two_words.html#draft-words",
    "title": "How useful are restaurant reviews? Google and Trip Advisor reviews in the Klang Valley, Malaysia",
    "section": "",
    "text": "In this second part of our analysis, we’ll be doing some text analytics. To recap, we are using data scraped by Ng Choon Khon containing restaurant reviews in Malaysia on Google and Trip Advisor. Take a look at the first part of this report to see the analysis of ratings as well as the dataset limitations.\nLet’s start with an overview of the most common bigrams (two consecutive words) that appear in Google reviews, broken down by rating.\nWhilst there isn’t too much in the plot below that is unexpected, it should be noted that our collective vocabulary, when it comes to restaurant reviews, is quite limited: “nice food” could indicate anything between three stars and five. Though we could argue that reviewers are being way too lenient by classing “nice food” as five stars.\nService, and not just food quality, is a major determinant in one-star ratings. This perhaps could be one of the reasons why fine dining restaurants have higher floors and ceilings for their ratings than more casual dining options.\n\n\n\n\n\n\n\n\n\n\n\nWhilst ratings might be very lenient overall – cheapening a five-star rating – we can at least say that there are definitely also qualitative differences between five-star and one-star reviews."
  }
]